{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9e17f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983126e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19120e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../models/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801eee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [StreamingStdOutCallbackHandler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee1743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ../models/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from '../models/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "llm = GPT4All(model=local_path, n_ctx=512, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf363c-406b-43a3-ae52-ae35e8ae335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"Your query here\"\n",
    "llm_chain.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
